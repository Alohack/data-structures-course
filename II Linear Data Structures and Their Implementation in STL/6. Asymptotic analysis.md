##### 6. Asymptotic analysis, Big O/Omega/Theta notation definitions, amortized analysis, examples

## Типы асимптотических обозначений в анализе сложности алгоритмов

Асимптотический анализ используется для измерения сложности алгоритма. Он помогает оценить, как ведет себя алгоритм при увеличении размера входных данных.

### 1. Верхняя граница (O-большое, Big-O Notation)
Обозначение $O$-большое используется для описания верхней границы времени выполнения алгоритма. Оно указывает на худший случай выполнения алгоритма.

**Определение:**
Функция $T(n)$ принадлежит $O(g(n))$, если существуют такие константы $c > 0$ и $n_0 \in \mathbb{N}$, что для всех $n \geq n_0$ выполняется:

$$T(n) \leq c \cdot g(n).$$

**Пример:**
Если $T(n) = 3n^2 + 5n + 7$, то $T(n)$ принадлежит $O(n^2)$, так как можно найти константы $c$ и $n_0$, например $c = 4$ и $n_0 = 1$.

**Достаточное условие:**
Для того, чтобы $T(n)$ принадлежит $O(g(n))$, достаточно чтобы:

$$\lim_{n \to \infty} \frac{T(n)}{g(n)} = c.$$

**Доказательство:**
Если выражение имеет конечный предел, то оно ограничено (по определению предела функции). Например:

$$\lim_{n \to \infty} \frac{T(n)}{g(n)} = c,$$

где $c > 0$. Это означает, что для достаточно больших $n$ отношение $g(n)$ стремится к константе $c$. Из определения предела следует, что для любого $\epsilon > 0$ существует $n_0 > 0$, такое что для всех $n \geq n_0$ выполняется:

$$
(c - \epsilon) \cdot g(n) < T(n) < (c + \epsilon) \cdot g(n).
$$

Выбор $\epsilon$: Пусть $\epsilon = \frac{c}{2}$. Тогда:

$$
T(n) \leq \frac{3c}{2} \cdot g(n), \quad \text{для всех } n \geq n_0.
$$

**Замечание:** Сходимость последовательнмости $\frac{T(n)}{g(n)}$ является достаточным, но не необходимым условием, так как легко можно самому придти к примеру, при котором $T(n)$ принадлежит $O(g(n))$, но предела $\lim\limits_{n \to \infty} \frac{T(n)}{g(n)}$ не существует.

### 2. Нижняя граница ($\Omega$-большое, Omega Notation)
Обозначение $\Omega$-большое используется для описания нижней границы времени выполнения алгоритма. Оно указывает на наилучший случай выполнения алгоритма.

**Определение:**
Функция $T(n)$ принадлежит $\Omega(g(n))$, если существуют такие константы $c > 0$ и $n_0 \geq 1$, что для всех $n \geq n_0$ выполняется:

$$T(n) \geq c \cdot g(n).$$

**Пример:**
Если $T(n) = 3n^2 + 5n + 7$, то $T(n)$ принадлежит $\Omega(n^2)$, так как можно найти константы $c$ и $n_0$, например $c = 2$ и $n_0 = 1$.

**Замечание:** Если $f$ принадлежит $\Omega(g)$, то $g$ принадлежит $O(f)$.

### 3. Точная граница ($\Theta$-обозначение, Theta Notation)
Обозначение $\Theta$ используется для описания точной границы времени выполнения алгоритма, то есть, когда функция одновременно находится в $O(g(n))$ и $\Omega(g(n))$.

**Определение:**
Функция $T(n)$ принадлежит $\Theta(g(n))$, если существуют такие константы $c_1 > 0$, $c_2 > 0$ и $n_0 \geq 1$, что для всех $n \geq n_0$ выполняется:

$$c_1 \cdot g(n) \leq T(n) \leq c_2 \cdot g(n).$$

**Пример:**
Если $T(n) = 3n^2 + 5n + 7$, то $T(n)$ принадлежит $\Theta(n^2)$.

---

## Амортизированный анализ

Рассмотрим амортизированный анализ на примере следующей функции:

```cpp
int f(int n)
{
  if(n & (n-1) != 0)
     return n+1;

  int sum = 0;
  for(int i = 0; i < n; ++i)
  {
    sum += 1;
  }
  return sum;
}
```

Легко заметить, что данная функция в худшем случае будет проводить $O(n)$ арифметических операций для вычисления значения переменной `sum`, но если выполняется условие `n & (n-1) != 0`  то будет выполнено лишь $O(1)$ арифметических операций.

Амортизированный анализ — это метод оценки средней стоимости операций в алгоритме.

Первый метод, который приходит на ум для вычисления среднего числа операций функции `f` - это вычисление арифметического среднего наихудшего и наилучшего сложностей функции `f`, в итоге имеем

$$
\frac{O(n) + O(1)} {2} = O\left(\frac{n+1}{2}\right) = O(n)
$$

Но такой подход никак не учитывает насколько часто выполняется условие `n & (n-1) != 0` и предполагает, что в половине случаев он выполняется, а в другой половине нет, хотя это не так.

Рассмотрим другой подход вычисления средней сложности операций функции `f`, в нем и заключается основной принцип амортизированного анализа.

### Основной принцип

Вызовем функцию `f` некоторое число раз (допустим `n` раз) для различных значений его аргумента, посчитаем общее число операций и разделим полученную сложность на `n`. Результат и будем называть амортизированной оценкой сложности операций функции `f`.

Как именно подбирвать значения для аргумента - предмет споров, сейчас же просто подберем значения в диапозоне ${1, 2, ..., n}$

```cpp
for(int k = 1; k <= n; ++k)
   f(k);
```

И так, данный код вызовет последовательно `f(1), f(2), ..., f(n)`. Возникает вопрос - насколько часто функция делает $O(n)$ действий, а насколько часто $O(1)$ действие? Это зависит от того когда `n & (n-1) != 0`.

Раз в предыдущем семестре у вас C++ являлся зачетным предметом, а ассемблер - экзаменационным, то Акопян предполагает, что каждый из вас легко сможет понять, что условие `n & (n-1) != 0` НЕ выполняется только, когда `n` является степенью двойки.

Таким образом мы приходим к следующей таблице сложностей

| `f(1)`  | `f(2)`  | `f(3)`  |  `f(4)` | `f(5)`  | `f(6)`  |  `f(7)` |  `f(8)` | ... |  `f(n)`  |
|---------|---------|---------|---------|---------|---------|---------|---------|-----|----------|
| $t_1=1$ | $t_2=2$ | $t_3=1$ | $t_4=4$ | $t_5=1$ | $t_6=1$ | $t_7=1$ | $t_8=8$ |     | $O(t_n)$ |

Где $t_k$ - число операций сложения, во время выполнения `f(k)`:

$$
t_k = \begin{cases}
k, \,\text{if  }\, k = 2^p \\
1, \, \text{else}
\end{cases}
$$

Вычислим же сумму всех $t_k$

$$
Т(n) := \sum\limits_{k=1}^n t_k = \sum\limits_{k \neq 2^p} t_k + \sum\limits_{k = 2^p} t_k = \sum\limits_{k \neq 2^p} 1 + \sum\limits_{k = 2^p} 2^p \leq n + (1+2+2^2+ ... + 2^p) = n + 2^{(p+1)}-1
$$

Так как $t_k \leq k \leq n$ следовательно $2^p \leq n$, таким образом

$$
T(n) \leq n + 2\cdot 2^{(p)}-1 \leq n+ 2\cdot n-1 = 3n-1
$$

Следовательно $T(n) = O(n)$

Мы вычислили общее число операций, если вызвать функцию `f` `n` раз. Вспомним, что для получения амортизированной оценки нужно величину `T(n)` разделить на `n`, полученная сложность и будет амортизированной оценкой функции `f`

$$
\frac{T(n)}{n} = \frac{O(n)}{n} = O(1)
$$

Таким образом функция `f` выполняется в худшем случае за $O(n)$, а амортизированная (средняя) оценка равна $O(1)$